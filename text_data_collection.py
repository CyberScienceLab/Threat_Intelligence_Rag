# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s_-FRW4YeAFmFmeYy9LBCACHSqoLEZdc
"""

import json
from OTXv2 import OTXv2, IndicatorTypes
import pandas as pd
from datetime import datetime, timedelta
from IPython.display import FileLink, display


# Import necessary libraries
def clean_and_parse_json(json_str):
    """
    Cleans and parses a JSON string to ensure it is correctly formatted.

    Args:
    - json_str (str): The JSON string to clean and parse.

    Returns:
    - dict or None: The parsed JSON object if successful, otherwise None.
    """
    print(f"Original JSON string: {json_str}")  # Debugging: print the original JSON string
    try:
        # Replace single quotes with double quotes for JSON compatibility
        json_str = json_str.replace("'", "\"")
        # Replace Python None with JSON null
        json_str = json_str.replace("None", "null")
        # Remove trailing commas in JSON objects and arrays which are invalid in JSON
        json_str = json_str.replace(", }", "}")
        json_str = json_str.replace(", ]", "]")
        # Print the cleaned JSON string for debugging purposes
        print(f"Cleaned JSON string: {json_str}")
        # Attempt to load the cleaned JSON string into a Python dictionary
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        # Print an error message if JSON decoding fails
        print(f"JSONDecodeError: {e} for row: {json_str}")
        return None

# Initialize OTXv2 instance with an API key (replace "ur key" with your actual API key)
otx = OTXv2("f30078a0f58994f4d66a99b1bc248771292f3aae1a1812124fa05dd6dd64fc44")
# Retrieve all pulses from OTX
pulses = otx.getall()
# Check the number of pulses retrieved
len(pulses)
# Normalize JSON data into a flat table and create a DataFrame
df = pd.json_normalize(pulses)
# Print the DataFrame to visualize the data structure
print(df)


# Read a CSV file into a DataFrame
df_pulse_1 = pd.read_csv("pulse_1.csv")
# Get a list of expected column names from the CSV
expected_columns = df_pulse_1.columns.tolist()
# Define the last relevant column up to which columns should be included
last_relevant_column = 'indicators'
# Extract only the relevant columns based on the last relevant column defined
relevant_columns = expected_columns[:expected_columns.index(last_relevant_column) + 1]

# Initialize a list to store filtered DataFrames
df_list = []

# Loop through each pulse retrieved from OTX
for pulse in pulses:
    df = pd.json_normalize(pulse) # Normalize JSON data for each pulse
    # Filter columns to include only up to 'indicators'
    df_filtered = df[relevant_columns]
    # Check if the DataFrame has exactly one row and matching columns
    if len(df_filtered) == 1 and set(df_filtered.columns) == set(relevant_columns):
        df_list.append(df_filtered) # Append the filtered DataFrame to the list

# Concatenate all filtered DataFrames into a single DataFrame
combined_df = pd.concat(df_list, ignore_index=True)

# Save the combined DataFrame to a CSV file
combined_df.to_csv("all_pulses_filtered.csv", index=False)


# Display a link to download the CSV file in the Jupyter Notebook
display(FileLink('all_pulses_filtered.csv'))
print("Saved all matching pulses to all_pulses_filtered.csv")

# Read the saved CSV file into a DataFrame for further processing
pulses_df = pd.read_csv("all_pulses_filtered.csv")

# Initialize a list to store extracted indicators
indicators_list = []

# Loop through each row in the pulses DataFrame
for index, row in pulses_df.iterrows():
    pulse_id = row['id'] # Extract pulse ID
    indicators = row['indicators'] # Extract indicators JSON string

    # Clean and parse the JSON data
    indicators_json = clean_and_parse_json(indicators)

    if indicators_json is not None: # If JSON parsing was successful
        # Loop through each indicator in the indicators list
        for indicator in indicators_json:
            # Add the pulse_id to the indicator data
            indicator['pulse_id'] = pulse_id # Add the pulse ID to each indicator
            indicators_list.append(indicator) # Append indicator to the list
    else:
        print(f"Row {index} has non-JSON format data: {indicators}")

# Normalize the list of indicators into a flat table
indicators_df = pd.json_normalize(indicators_list)

# Save the extracted indicators to a CSV file
indicators_df.to_csv("indicators_extracted.csv", index=False)

print("Saved all extracted indicators to indicators_extracted.csv")